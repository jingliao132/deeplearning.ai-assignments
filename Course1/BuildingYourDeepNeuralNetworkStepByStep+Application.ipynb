{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v2 import *\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]\n",
      " [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]\n",
      " [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]\n",
      " [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]\n",
      "b1 = [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "W2 = [[-0.01185047 -0.0020565   0.01486148  0.00236716]\n",
      " [-0.01023785 -0.00712993  0.00625245 -0.00160513]\n",
      " [-0.00768836 -0.00230031  0.00745056  0.01976111]]\n",
      "b2 = [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    }
   ],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    L = len(layer_dims)\n",
    "    params = {}\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        params['W'+str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "        params['b'+str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        assert(params['W'+str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(params['b'+str(l)].shape == (layer_dims[l], 1))\n",
    "        \n",
    "    return params\n",
    "\n",
    "parameters = initialize_parameters_deep([5,4,3])\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With sigmoid: A = [[ 0.96890023  0.11013289]]\n",
      "With ReLU: A = [[ 3.43896131  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def linear_activation_forward(A_pre, W, b, activation):\n",
    "    Z = np.dot(W, A_pre) + b    #\n",
    "    if activation == 'sigmoid':\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == 'relu':\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    linear_cache = (A_pre, W, b)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n",
    "\n",
    "A_prev, W, b = linear_activation_forward_test_case()\n",
    "#print 'A_prev.shape =', A_prev.shape\n",
    "#print 'W.shape =', W.shape\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"sigmoid\")\n",
    "print(\"With sigmoid: A = \" + str(A))\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"relu\")\n",
    "print(\"With ReLU: A = \" + str(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL = [[ 0.17007265  0.2524272 ]]\n",
      "Length of caches list = 2\n"
     ]
    }
   ],
   "source": [
    "def L_model_forward(X, params):\n",
    "    L = len(params) / 2\n",
    "    caches = []\n",
    "    A_pre = X\n",
    "    for l in range(1, L):\n",
    "        A, cache = linear_activation_forward(A_pre, params['W'+str(l)], params['b'+str(l)], 'relu')\n",
    "        A_pre = A\n",
    "        caches.append(cache)\n",
    "    A_L, cache = linear_activation_forward(A_pre, params['W'+str(L)], params['b'+str(L)], 'sigmoid')\n",
    "    caches.append(cache)\n",
    "    return A_L, caches\n",
    "\n",
    "X, parameters = L_model_forward_test_case()\n",
    "AL, caches = L_model_forward(X, parameters)\n",
    "print(\"AL = \" + str(AL))\n",
    "print(\"Length of caches list = \" + str(len(caches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.414931599615\n"
     ]
    }
   ],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -1.0 / m * np.sum(Y * np.log(AL) + (1-Y) * np.log(1-AL))\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())    # cost should be a scaler\n",
    "    return cost\n",
    "\n",
    "Y, AL = compute_cost_test_case()\n",
    "print(\"cost = \" + str(compute_cost(AL, Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid:\n",
      "dA_prev = [[ 0.11017994  0.01105339]\n",
      " [ 0.09466817  0.00949723]\n",
      " [-0.05743092 -0.00576154]]\n",
      "dW = [[ 0.10266786  0.09778551 -0.01968084]]\n",
      "db = [[-0.05729622]]\n",
      "\n",
      "relu:\n",
      "dA_prev = [[ 0.44090989  0.        ]\n",
      " [ 0.37883606  0.        ]\n",
      " [-0.2298228   0.        ]]\n",
      "dW = [[ 0.44513824  0.37371418 -0.10478989]]\n",
      "db = [[-0.20837892]]\n"
     ]
    }
   ],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    #linear_cache = cache[0]\n",
    "    #activation_cache = cache[1]\n",
    "    linear_cache, activation_cache = cache    # more simple\n",
    "    #A_pre = linear_cache[0]\n",
    "    #W = linear_cache[1]\n",
    "    #b = linear_cache[2]\n",
    "    A_pre, W, b = linear_cache    # more simple\n",
    "    m = dA.shape[1]\n",
    "    \n",
    "    if activation == 'sigmoid':\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "    elif activation == 'relu':\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "    \n",
    "    dW = 1.0 / m * np.dot(dZ, A_pre.T)\n",
    "    db = 1.0 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_pre = np.dot(W.T, dZ)\n",
    "        \n",
    "    assert(dA_pre.shape == A_pre.shape)\n",
    "    assert(dW.shape == W.shape)\n",
    "    assert(db.shape == b.shape)\n",
    "    return dA_pre, dW, db\n",
    "\n",
    "dAL, linear_activation_cache = linear_activation_backward_test_case()\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = \"sigmoid\")\n",
    "print (\"sigmoid:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db) + \"\\n\")\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = \"relu\")\n",
    "print (\"relu:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1 = [[ 0.41010002  0.07807203  0.13798444  0.10502167]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.05283652  0.01005865  0.01777766  0.0135308 ]]\n",
      "db1 = [[-0.22007063]\n",
      " [ 0.        ]\n",
      " [-0.02835349]]\n",
      "dA1 = [[ 0.          0.52257901]\n",
      " [ 0.         -0.3269206 ]\n",
      " [ 0.         -0.32070404]\n",
      " [ 0.         -0.74079187]]\n"
     ]
    }
   ],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    L = len(caches)\n",
    "    #print 'L =', L\n",
    "    m = Y.shape[1]\n",
    "    grads = {}\n",
    "    \n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    # grads['dA'+str(L-1)], grads['dW'+str(L)], grads['db'+str(L)] = linear_activation_bacward(dAL, caches[L], activation='sigmoid')\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, caches[L-1], \"sigmoid\")    # cache is a list starting from 0\n",
    "    for l in reversed(range(1, L)):    # need not compute dA0, dW0, db0\n",
    "        #print 'l =', l\n",
    "        current_cache = caches[l-1]\n",
    "        grads['dA'+str(l)], grads['dW'+str(l)], grads['db'+str(l)] = linear_activation_backward(grads['dA'+str(l+1)], current_cache, activation = 'relu')\n",
    "    \n",
    "    return grads\n",
    "\n",
    "AL, Y_assess, caches = L_model_backward_test_case()\n",
    "grads = L_model_backward(AL, Y_assess, caches)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dA1 = \"+ str(grads[\"dA1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.59562069 -0.09991781 -2.14584584  1.82662008]\n",
      " [-1.76569676 -0.80627147  0.51115557 -1.18258802]\n",
      " [-1.0535704  -0.86128581  0.68284052  2.20374577]]\n",
      "b1 = [[-0.04659241]\n",
      " [-1.28888275]\n",
      " [ 0.53405496]]\n",
      "W2 = [[-0.55569196  0.0354055   1.32964895]]\n",
      "b2 = [[-0.84610769]]\n"
     ]
    }
   ],
   "source": [
    "def update_parameters(params, grads, learning_rate):\n",
    "    L = len(params) / 2\n",
    "    for l in range(L):\n",
    "        params['W'+str(l+1)] = params['W'+str(l+1)] - learning_rate * grads['dW'+str(l+1)]\n",
    "        params['b'+str(l+1)] = params['b'+str(l+1)] - learning_rate * grads['db'+str(l+1)]\n",
    "    \n",
    "    return params\n",
    "\n",
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = update_parameters(parameters, grads, 0.1)\n",
    "\n",
    "print (\"W1 = \"+ str(parameters[\"W1\"]))\n",
    "print (\"b1 = \"+ str(parameters[\"b1\"]))\n",
    "print (\"W2 = \"+ str(parameters[\"W2\"]))\n",
    "print (\"b2 = \"+ str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layer_dims, learning_rate=0.0075, iter_num=3000, print_cost=False):\n",
    "    np.random.seed(1)\n",
    "    costs = []\n",
    "    \n",
    "    params = initialize_parameters_deep(layer_dims)\n",
    "    for i in range(iter_num):\n",
    "        AL, caches = L_model_forward(X, params)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        params = update_parameters(params, grads, learning_rate)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            costs.append(cost)\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Number of training examples: 209\n",
      "Number of testing examples: 50\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_x_orig shape: (209, 64, 64, 3)\n",
      "train_y shape: (1, 209)\n",
      "test_x_orig shape: (50, 64, 64, 3)\n",
      "test_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "m_train = train_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "m_test = test_x_orig.shape[0]\n",
    "\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples: \" + str(m_test))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (12288, 209)\n",
      "test_x's shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training and test examples \n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.771749\n",
      "Cost after iteration 100: 0.672053\n",
      "Cost after iteration 200: 0.648263\n",
      "Cost after iteration 300: 0.611507\n",
      "Cost after iteration 400: 0.567047\n",
      "Cost after iteration 500: 0.540138\n",
      "Cost after iteration 600: 0.527930\n",
      "Cost after iteration 700: 0.465477\n",
      "Cost after iteration 800: 0.369126\n",
      "Cost after iteration 900: 0.391747\n",
      "Cost after iteration 1000: 0.315187\n",
      "Cost after iteration 1100: 0.272700\n",
      "Cost after iteration 1200: 0.237419\n",
      "Cost after iteration 1300: 0.199601\n",
      "Cost after iteration 1400: 0.189263\n",
      "Cost after iteration 1500: 0.161189\n",
      "Cost after iteration 1600: 0.148214\n",
      "Cost after iteration 1700: 0.137775\n",
      "Cost after iteration 1800: 0.129740\n",
      "Cost after iteration 1900: 0.121225\n",
      "Cost after iteration 2000: 0.113821\n",
      "Cost after iteration 2100: 0.107839\n",
      "Cost after iteration 2200: 0.102855\n",
      "Cost after iteration 2300: 0.100897\n",
      "Cost after iteration 2400: 0.092878\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAEWCAYAAAAJjn7zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47980e0d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers_dims = [12288, 20, 7, 5, 1] #  5-layer model\n",
    "parameters = L_layer_model(train_x, train_y, layers_dims, iter_num = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
